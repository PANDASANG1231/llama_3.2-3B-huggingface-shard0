{"metadata": {"total_size": 6425499648}, "weight_map": {"model.embed_tokens.weight": "embed_tokens.safetensors", "model.layers.0.input_layernorm.weight": "model-00001-model.layers.0.input_layernorm.weight.safetensors", "model.layers.0.mlp.down_proj.weight": "model-00002-model.layers.0.mlp.down_proj.weight.safetensors", "model.layers.0.mlp.gate_proj.weight": "model-00003-model.layers.0.mlp.gate_proj.weight.safetensors", "model.layers.0.mlp.up_proj.weight": "model-00004-model.layers.0.mlp.up_proj.weight.safetensors", "model.layers.0.post_attention_layernorm.weight": "model-00005-model.layers.0.post_attention_layernorm.weight.safetensors", "model.layers.0.self_attn.k_proj.weight": "model-00006-model.layers.0.self_attn.k_proj.weight.safetensors", "model.layers.0.self_attn.o_proj.weight": "model-00007-model.layers.0.self_attn.o_proj.weight.safetensors", "model.layers.0.self_attn.q_proj.weight": "model-00008-model.layers.0.self_attn.q_proj.weight.safetensors", "model.layers.0.self_attn.v_proj.weight": "model-00009-model.layers.0.self_attn.v_proj.weight.safetensors", "model.layers.1.input_layernorm.weight": "model-00010-model.layers.1.input_layernorm.weight.safetensors", "model.layers.1.mlp.down_proj.weight": "model-00011-model.layers.1.mlp.down_proj.weight.safetensors", "model.layers.1.mlp.gate_proj.weight": "model-00012-model.layers.1.mlp.gate_proj.weight.safetensors", "model.layers.1.mlp.up_proj.weight": "model-00013-model.layers.1.mlp.up_proj.weight.safetensors", "model.layers.1.post_attention_layernorm.weight": "model-00014-model.layers.1.post_attention_layernorm.weight.safetensors", "model.layers.1.self_attn.k_proj.weight": "model-00015-model.layers.1.self_attn.k_proj.weight.safetensors", "model.layers.1.self_attn.o_proj.weight": "model-00016-model.layers.1.self_attn.o_proj.weight.safetensors", "model.layers.1.self_attn.q_proj.weight": "model-00017-model.layers.1.self_attn.q_proj.weight.safetensors", "model.layers.1.self_attn.v_proj.weight": "model-00018-model.layers.1.self_attn.v_proj.weight.safetensors", "model.layers.10.input_layernorm.weight": "model-00019-model.layers.10.input_layernorm.weight.safetensors", "model.layers.10.mlp.down_proj.weight": "model-00020-model.layers.10.mlp.down_proj.weight.safetensors", "model.layers.10.mlp.gate_proj.weight": "model-00021-model.layers.10.mlp.gate_proj.weight.safetensors", "model.layers.10.mlp.up_proj.weight": "model-00022-model.layers.10.mlp.up_proj.weight.safetensors", "model.layers.10.post_attention_layernorm.weight": "model-00023-model.layers.10.post_attention_layernorm.weight.safetensors", "model.layers.10.self_attn.k_proj.weight": "model-00024-model.layers.10.self_attn.k_proj.weight.safetensors", "model.layers.10.self_attn.o_proj.weight": "model-00025-model.layers.10.self_attn.o_proj.weight.safetensors", "model.layers.10.self_attn.q_proj.weight": "model-00026-model.layers.10.self_attn.q_proj.weight.safetensors", "model.layers.10.self_attn.v_proj.weight": "model-00027-model.layers.10.self_attn.v_proj.weight.safetensors", "model.layers.11.input_layernorm.weight": "model-00028-model.layers.11.input_layernorm.weight.safetensors", "model.layers.11.mlp.down_proj.weight": "model-00029-model.layers.11.mlp.down_proj.weight.safetensors", "model.layers.11.mlp.gate_proj.weight": "model-00030-model.layers.11.mlp.gate_proj.weight.safetensors", "model.layers.11.mlp.up_proj.weight": "model-00031-model.layers.11.mlp.up_proj.weight.safetensors", "model.layers.11.post_attention_layernorm.weight": "model-00032-model.layers.11.post_attention_layernorm.weight.safetensors", "model.layers.11.self_attn.k_proj.weight": "model-00033-model.layers.11.self_attn.k_proj.weight.safetensors", "model.layers.11.self_attn.o_proj.weight": "model-00034-model.layers.11.self_attn.o_proj.weight.safetensors", "model.layers.11.self_attn.q_proj.weight": "model-00035-model.layers.11.self_attn.q_proj.weight.safetensors", "model.layers.11.self_attn.v_proj.weight": "model-00036-model.layers.11.self_attn.v_proj.weight.safetensors", "model.layers.12.input_layernorm.weight": "model-00037-model.layers.12.input_layernorm.weight.safetensors", "model.layers.12.mlp.down_proj.weight": "model-00038-model.layers.12.mlp.down_proj.weight.safetensors", "model.layers.12.mlp.gate_proj.weight": "model-00039-model.layers.12.mlp.gate_proj.weight.safetensors", "model.layers.12.mlp.up_proj.weight": "model-00040-model.layers.12.mlp.up_proj.weight.safetensors", "model.layers.12.post_attention_layernorm.weight": "model-00041-model.layers.12.post_attention_layernorm.weight.safetensors", "model.layers.12.self_attn.k_proj.weight": "model-00042-model.layers.12.self_attn.k_proj.weight.safetensors", "model.layers.12.self_attn.o_proj.weight": "model-00043-model.layers.12.self_attn.o_proj.weight.safetensors", "model.layers.12.self_attn.q_proj.weight": "model-00044-model.layers.12.self_attn.q_proj.weight.safetensors", "model.layers.12.self_attn.v_proj.weight": "model-00045-model.layers.12.self_attn.v_proj.weight.safetensors", "model.layers.13.input_layernorm.weight": "model-00046-model.layers.13.input_layernorm.weight.safetensors", "model.layers.13.mlp.down_proj.weight": "model-00047-model.layers.13.mlp.down_proj.weight.safetensors", "model.layers.13.mlp.gate_proj.weight": "model-00048-model.layers.13.mlp.gate_proj.weight.safetensors", "model.layers.13.mlp.up_proj.weight": "model-00049-model.layers.13.mlp.up_proj.weight.safetensors", "model.layers.13.post_attention_layernorm.weight": "model-00050-model.layers.13.post_attention_layernorm.weight.safetensors", "model.layers.13.self_attn.k_proj.weight": "model-00051-model.layers.13.self_attn.k_proj.weight.safetensors", "model.layers.13.self_attn.o_proj.weight": "model-00052-model.layers.13.self_attn.o_proj.weight.safetensors", "model.layers.13.self_attn.q_proj.weight": "model-00053-model.layers.13.self_attn.q_proj.weight.safetensors", "model.layers.13.self_attn.v_proj.weight": "model-00054-model.layers.13.self_attn.v_proj.weight.safetensors", "model.layers.14.input_layernorm.weight": "model-00055-model.layers.14.input_layernorm.weight.safetensors", "model.layers.14.mlp.down_proj.weight": "model-00056-model.layers.14.mlp.down_proj.weight.safetensors", "model.layers.14.mlp.gate_proj.weight": "model-00057-model.layers.14.mlp.gate_proj.weight.safetensors", "model.layers.14.mlp.up_proj.weight": "model-00058-model.layers.14.mlp.up_proj.weight.safetensors", "model.layers.14.post_attention_layernorm.weight": "model-00059-model.layers.14.post_attention_layernorm.weight.safetensors", "model.layers.14.self_attn.k_proj.weight": "model-00060-model.layers.14.self_attn.k_proj.weight.safetensors", "model.layers.14.self_attn.o_proj.weight": "model-00061-model.layers.14.self_attn.o_proj.weight.safetensors", "model.layers.14.self_attn.q_proj.weight": "model-00062-model.layers.14.self_attn.q_proj.weight.safetensors", "model.layers.14.self_attn.v_proj.weight": "model-00063-model.layers.14.self_attn.v_proj.weight.safetensors", "model.layers.15.input_layernorm.weight": "model-00064-model.layers.15.input_layernorm.weight.safetensors", "model.layers.15.mlp.down_proj.weight": "model-00065-model.layers.15.mlp.down_proj.weight.safetensors", "model.layers.15.mlp.gate_proj.weight": "model-00066-model.layers.15.mlp.gate_proj.weight.safetensors", "model.layers.15.mlp.up_proj.weight": "model-00067-model.layers.15.mlp.up_proj.weight.safetensors", "model.layers.15.post_attention_layernorm.weight": "model-00068-model.layers.15.post_attention_layernorm.weight.safetensors", "model.layers.15.self_attn.k_proj.weight": "model-00069-model.layers.15.self_attn.k_proj.weight.safetensors", "model.layers.15.self_attn.o_proj.weight": "model-00070-model.layers.15.self_attn.o_proj.weight.safetensors", "model.layers.15.self_attn.q_proj.weight": "model-00071-model.layers.15.self_attn.q_proj.weight.safetensors", "model.layers.15.self_attn.v_proj.weight": "model-00072-model.layers.15.self_attn.v_proj.weight.safetensors", "model.layers.16.input_layernorm.weight": "model-00073-model.layers.16.input_layernorm.weight.safetensors", "model.layers.16.mlp.down_proj.weight": "model-00074-model.layers.16.mlp.down_proj.weight.safetensors", "model.layers.16.mlp.gate_proj.weight": "model-00075-model.layers.16.mlp.gate_proj.weight.safetensors", "model.layers.16.mlp.up_proj.weight": "model-00076-model.layers.16.mlp.up_proj.weight.safetensors", "model.layers.16.post_attention_layernorm.weight": "model-00077-model.layers.16.post_attention_layernorm.weight.safetensors", "model.layers.16.self_attn.k_proj.weight": "model-00078-model.layers.16.self_attn.k_proj.weight.safetensors", "model.layers.16.self_attn.o_proj.weight": "model-00079-model.layers.16.self_attn.o_proj.weight.safetensors", "model.layers.16.self_attn.q_proj.weight": "model-00080-model.layers.16.self_attn.q_proj.weight.safetensors", "model.layers.16.self_attn.v_proj.weight": "model-00081-model.layers.16.self_attn.v_proj.weight.safetensors", "model.layers.17.input_layernorm.weight": "model-00082-model.layers.17.input_layernorm.weight.safetensors", "model.layers.17.mlp.down_proj.weight": "model-00083-model.layers.17.mlp.down_proj.weight.safetensors", "model.layers.17.mlp.gate_proj.weight": "model-00084-model.layers.17.mlp.gate_proj.weight.safetensors", "model.layers.17.mlp.up_proj.weight": "model-00085-model.layers.17.mlp.up_proj.weight.safetensors", "model.layers.17.post_attention_layernorm.weight": "model-00086-model.layers.17.post_attention_layernorm.weight.safetensors", "model.layers.17.self_attn.k_proj.weight": "model-00087-model.layers.17.self_attn.k_proj.weight.safetensors", "model.layers.17.self_attn.o_proj.weight": "model-00088-model.layers.17.self_attn.o_proj.weight.safetensors", "model.layers.17.self_attn.q_proj.weight": "model-00089-model.layers.17.self_attn.q_proj.weight.safetensors", "model.layers.17.self_attn.v_proj.weight": "model-00090-model.layers.17.self_attn.v_proj.weight.safetensors", "model.layers.18.input_layernorm.weight": "model-00091-model.layers.18.input_layernorm.weight.safetensors", "model.layers.18.mlp.down_proj.weight": "model-00092-model.layers.18.mlp.down_proj.weight.safetensors", "model.layers.18.mlp.gate_proj.weight": "model-00093-model.layers.18.mlp.gate_proj.weight.safetensors", "model.layers.18.mlp.up_proj.weight": "model-00094-model.layers.18.mlp.up_proj.weight.safetensors", "model.layers.18.post_attention_layernorm.weight": "model-00095-model.layers.18.post_attention_layernorm.weight.safetensors", "model.layers.18.self_attn.k_proj.weight": "model-00096-model.layers.18.self_attn.k_proj.weight.safetensors", "model.layers.18.self_attn.o_proj.weight": "model-00097-model.layers.18.self_attn.o_proj.weight.safetensors", "model.layers.18.self_attn.q_proj.weight": "model-00098-model.layers.18.self_attn.q_proj.weight.safetensors", "model.layers.18.self_attn.v_proj.weight": "model-00099-model.layers.18.self_attn.v_proj.weight.safetensors", "model.layers.19.input_layernorm.weight": "model-00100-model.layers.19.input_layernorm.weight.safetensors", "model.layers.19.mlp.down_proj.weight": "model-00101-model.layers.19.mlp.down_proj.weight.safetensors", "model.layers.19.mlp.gate_proj.weight": "model-00102-model.layers.19.mlp.gate_proj.weight.safetensors", "model.layers.19.mlp.up_proj.weight": "model-00103-model.layers.19.mlp.up_proj.weight.safetensors", "model.layers.19.post_attention_layernorm.weight": "model-00104-model.layers.19.post_attention_layernorm.weight.safetensors", "model.layers.19.self_attn.k_proj.weight": "model-00105-model.layers.19.self_attn.k_proj.weight.safetensors", "model.layers.19.self_attn.o_proj.weight": "model-00106-model.layers.19.self_attn.o_proj.weight.safetensors", "model.layers.19.self_attn.q_proj.weight": "model-00107-model.layers.19.self_attn.q_proj.weight.safetensors", "model.layers.19.self_attn.v_proj.weight": "model-00108-model.layers.19.self_attn.v_proj.weight.safetensors", "model.layers.2.input_layernorm.weight": "model-00109-model.layers.2.input_layernorm.weight.safetensors", "model.layers.2.mlp.down_proj.weight": "model-00110-model.layers.2.mlp.down_proj.weight.safetensors", "model.layers.2.mlp.gate_proj.weight": "model-00111-model.layers.2.mlp.gate_proj.weight.safetensors", "model.layers.2.mlp.up_proj.weight": "model-00112-model.layers.2.mlp.up_proj.weight.safetensors", "model.layers.2.post_attention_layernorm.weight": "model-00113-model.layers.2.post_attention_layernorm.weight.safetensors", "model.layers.2.self_attn.k_proj.weight": "model-00114-model.layers.2.self_attn.k_proj.weight.safetensors", "model.layers.2.self_attn.o_proj.weight": "model-00115-model.layers.2.self_attn.o_proj.weight.safetensors", "model.layers.2.self_attn.q_proj.weight": "model-00116-model.layers.2.self_attn.q_proj.weight.safetensors", "model.layers.2.self_attn.v_proj.weight": "model-00117-model.layers.2.self_attn.v_proj.weight.safetensors", "model.layers.20.input_layernorm.weight": "model-00187-model.layers.20.input_layernorm.weight.safetensors", "model.layers.20.mlp.down_proj.weight": "model-00188-model.layers.20.mlp.down_proj.weight.safetensors", "model.layers.20.mlp.gate_proj.weight": "model-00118-model.layers.20.mlp.gate_proj.weight.safetensors", "model.layers.20.mlp.up_proj.weight": "model-00119-model.layers.20.mlp.up_proj.weight.safetensors", "model.layers.20.post_attention_layernorm.weight": "model-00189-model.layers.20.post_attention_layernorm.weight.safetensors", "model.layers.20.self_attn.k_proj.weight": "model-00120-model.layers.20.self_attn.k_proj.weight.safetensors", "model.layers.20.self_attn.o_proj.weight": "model-00121-model.layers.20.self_attn.o_proj.weight.safetensors", "model.layers.20.self_attn.q_proj.weight": "model-00122-model.layers.20.self_attn.q_proj.weight.safetensors", "model.layers.20.self_attn.v_proj.weight": "model-00123-model.layers.20.self_attn.v_proj.weight.safetensors", "model.layers.21.input_layernorm.weight": "model-00190-model.layers.21.input_layernorm.weight.safetensors", "model.layers.21.mlp.down_proj.weight": "model-00191-model.layers.21.mlp.down_proj.weight.safetensors", "model.layers.21.mlp.gate_proj.weight": "model-00192-model.layers.21.mlp.gate_proj.weight.safetensors", "model.layers.21.mlp.up_proj.weight": "model-00193-model.layers.21.mlp.up_proj.weight.safetensors", "model.layers.21.post_attention_layernorm.weight": "model-00194-model.layers.21.post_attention_layernorm.weight.safetensors", "model.layers.21.self_attn.k_proj.weight": "model-00195-model.layers.21.self_attn.k_proj.weight.safetensors", "model.layers.21.self_attn.o_proj.weight": "model-00196-model.layers.21.self_attn.o_proj.weight.safetensors", "model.layers.21.self_attn.q_proj.weight": "model-00197-model.layers.21.self_attn.q_proj.weight.safetensors", "model.layers.21.self_attn.v_proj.weight": "model-00198-model.layers.21.self_attn.v_proj.weight.safetensors", "model.layers.22.input_layernorm.weight": "model-00199-model.layers.22.input_layernorm.weight.safetensors", "model.layers.22.mlp.down_proj.weight": "model-00200-model.layers.22.mlp.down_proj.weight.safetensors", "model.layers.22.mlp.gate_proj.weight": "model-00201-model.layers.22.mlp.gate_proj.weight.safetensors", "model.layers.22.mlp.up_proj.weight": "model-00202-model.layers.22.mlp.up_proj.weight.safetensors", "model.layers.22.post_attention_layernorm.weight": "model-00203-model.layers.22.post_attention_layernorm.weight.safetensors", "model.layers.22.self_attn.k_proj.weight": "model-00204-model.layers.22.self_attn.k_proj.weight.safetensors", "model.layers.22.self_attn.o_proj.weight": "model-00205-model.layers.22.self_attn.o_proj.weight.safetensors", "model.layers.22.self_attn.q_proj.weight": "model-00206-model.layers.22.self_attn.q_proj.weight.safetensors", "model.layers.22.self_attn.v_proj.weight": "model-00207-model.layers.22.self_attn.v_proj.weight.safetensors", "model.layers.23.input_layernorm.weight": "model-00208-model.layers.23.input_layernorm.weight.safetensors", "model.layers.23.mlp.down_proj.weight": "model-00209-model.layers.23.mlp.down_proj.weight.safetensors", "model.layers.23.mlp.gate_proj.weight": "model-00210-model.layers.23.mlp.gate_proj.weight.safetensors", "model.layers.23.mlp.up_proj.weight": "model-00211-model.layers.23.mlp.up_proj.weight.safetensors", "model.layers.23.post_attention_layernorm.weight": "model-00212-model.layers.23.post_attention_layernorm.weight.safetensors", "model.layers.23.self_attn.k_proj.weight": "model-00213-model.layers.23.self_attn.k_proj.weight.safetensors", "model.layers.23.self_attn.o_proj.weight": "model-00214-model.layers.23.self_attn.o_proj.weight.safetensors", "model.layers.23.self_attn.q_proj.weight": "model-00215-model.layers.23.self_attn.q_proj.weight.safetensors", "model.layers.23.self_attn.v_proj.weight": "model-00216-model.layers.23.self_attn.v_proj.weight.safetensors", "model.layers.24.input_layernorm.weight": "model-00217-model.layers.24.input_layernorm.weight.safetensors", "model.layers.24.mlp.down_proj.weight": "model-00218-model.layers.24.mlp.down_proj.weight.safetensors", "model.layers.24.mlp.gate_proj.weight": "model-00219-model.layers.24.mlp.gate_proj.weight.safetensors", "model.layers.24.mlp.up_proj.weight": "model-00220-model.layers.24.mlp.up_proj.weight.safetensors", "model.layers.24.post_attention_layernorm.weight": "model-00221-model.layers.24.post_attention_layernorm.weight.safetensors", "model.layers.24.self_attn.k_proj.weight": "model-00222-model.layers.24.self_attn.k_proj.weight.safetensors", "model.layers.24.self_attn.o_proj.weight": "model-00223-model.layers.24.self_attn.o_proj.weight.safetensors", "model.layers.24.self_attn.q_proj.weight": "model-00224-model.layers.24.self_attn.q_proj.weight.safetensors", "model.layers.24.self_attn.v_proj.weight": "model-00225-model.layers.24.self_attn.v_proj.weight.safetensors", "model.layers.25.input_layernorm.weight": "model-00226-model.layers.25.input_layernorm.weight.safetensors", "model.layers.25.mlp.down_proj.weight": "model-00227-model.layers.25.mlp.down_proj.weight.safetensors", "model.layers.25.mlp.gate_proj.weight": "model-00228-model.layers.25.mlp.gate_proj.weight.safetensors", "model.layers.25.mlp.up_proj.weight": "model-00229-model.layers.25.mlp.up_proj.weight.safetensors", "model.layers.25.post_attention_layernorm.weight": "model-00230-model.layers.25.post_attention_layernorm.weight.safetensors", "model.layers.25.self_attn.k_proj.weight": "model-00231-model.layers.25.self_attn.k_proj.weight.safetensors", "model.layers.25.self_attn.o_proj.weight": "model-00232-model.layers.25.self_attn.o_proj.weight.safetensors", "model.layers.25.self_attn.q_proj.weight": "model-00233-model.layers.25.self_attn.q_proj.weight.safetensors", "model.layers.25.self_attn.v_proj.weight": "model-00234-model.layers.25.self_attn.v_proj.weight.safetensors", "model.layers.26.input_layernorm.weight": "model-00235-model.layers.26.input_layernorm.weight.safetensors", "model.layers.26.mlp.down_proj.weight": "model-00236-model.layers.26.mlp.down_proj.weight.safetensors", "model.layers.26.mlp.gate_proj.weight": "model-00237-model.layers.26.mlp.gate_proj.weight.safetensors", "model.layers.26.mlp.up_proj.weight": "model-00238-model.layers.26.mlp.up_proj.weight.safetensors", "model.layers.26.post_attention_layernorm.weight": "model-00239-model.layers.26.post_attention_layernorm.weight.safetensors", "model.layers.26.self_attn.k_proj.weight": "model-00240-model.layers.26.self_attn.k_proj.weight.safetensors", "model.layers.26.self_attn.o_proj.weight": "model-00241-model.layers.26.self_attn.o_proj.weight.safetensors", "model.layers.26.self_attn.q_proj.weight": "model-00242-model.layers.26.self_attn.q_proj.weight.safetensors", "model.layers.26.self_attn.v_proj.weight": "model-00243-model.layers.26.self_attn.v_proj.weight.safetensors", "model.layers.27.input_layernorm.weight": "model-00244-model.layers.27.input_layernorm.weight.safetensors", "model.layers.27.mlp.down_proj.weight": "model-00245-model.layers.27.mlp.down_proj.weight.safetensors", "model.layers.27.mlp.gate_proj.weight": "model-00246-model.layers.27.mlp.gate_proj.weight.safetensors", "model.layers.27.mlp.up_proj.weight": "model-00247-model.layers.27.mlp.up_proj.weight.safetensors", "model.layers.27.post_attention_layernorm.weight": "model-00248-model.layers.27.post_attention_layernorm.weight.safetensors", "model.layers.27.self_attn.k_proj.weight": "model-00249-model.layers.27.self_attn.k_proj.weight.safetensors", "model.layers.27.self_attn.o_proj.weight": "model-00250-model.layers.27.self_attn.o_proj.weight.safetensors", "model.layers.27.self_attn.q_proj.weight": "model-00251-model.layers.27.self_attn.q_proj.weight.safetensors", "model.layers.27.self_attn.v_proj.weight": "model-00252-model.layers.27.self_attn.v_proj.weight.safetensors", "model.layers.3.input_layernorm.weight": "model-00124-model.layers.3.input_layernorm.weight.safetensors", "model.layers.3.mlp.down_proj.weight": "model-00125-model.layers.3.mlp.down_proj.weight.safetensors", "model.layers.3.mlp.gate_proj.weight": "model-00126-model.layers.3.mlp.gate_proj.weight.safetensors", "model.layers.3.mlp.up_proj.weight": "model-00127-model.layers.3.mlp.up_proj.weight.safetensors", "model.layers.3.post_attention_layernorm.weight": "model-00128-model.layers.3.post_attention_layernorm.weight.safetensors", "model.layers.3.self_attn.k_proj.weight": "model-00129-model.layers.3.self_attn.k_proj.weight.safetensors", "model.layers.3.self_attn.o_proj.weight": "model-00130-model.layers.3.self_attn.o_proj.weight.safetensors", "model.layers.3.self_attn.q_proj.weight": "model-00131-model.layers.3.self_attn.q_proj.weight.safetensors", "model.layers.3.self_attn.v_proj.weight": "model-00132-model.layers.3.self_attn.v_proj.weight.safetensors", "model.layers.4.input_layernorm.weight": "model-00133-model.layers.4.input_layernorm.weight.safetensors", "model.layers.4.mlp.down_proj.weight": "model-00134-model.layers.4.mlp.down_proj.weight.safetensors", "model.layers.4.mlp.gate_proj.weight": "model-00135-model.layers.4.mlp.gate_proj.weight.safetensors", "model.layers.4.mlp.up_proj.weight": "model-00136-model.layers.4.mlp.up_proj.weight.safetensors", "model.layers.4.post_attention_layernorm.weight": "model-00137-model.layers.4.post_attention_layernorm.weight.safetensors", "model.layers.4.self_attn.k_proj.weight": "model-00138-model.layers.4.self_attn.k_proj.weight.safetensors", "model.layers.4.self_attn.o_proj.weight": "model-00139-model.layers.4.self_attn.o_proj.weight.safetensors", "model.layers.4.self_attn.q_proj.weight": "model-00140-model.layers.4.self_attn.q_proj.weight.safetensors", "model.layers.4.self_attn.v_proj.weight": "model-00141-model.layers.4.self_attn.v_proj.weight.safetensors", "model.layers.5.input_layernorm.weight": "model-00142-model.layers.5.input_layernorm.weight.safetensors", "model.layers.5.mlp.down_proj.weight": "model-00143-model.layers.5.mlp.down_proj.weight.safetensors", "model.layers.5.mlp.gate_proj.weight": "model-00144-model.layers.5.mlp.gate_proj.weight.safetensors", "model.layers.5.mlp.up_proj.weight": "model-00145-model.layers.5.mlp.up_proj.weight.safetensors", "model.layers.5.post_attention_layernorm.weight": "model-00146-model.layers.5.post_attention_layernorm.weight.safetensors", "model.layers.5.self_attn.k_proj.weight": "model-00147-model.layers.5.self_attn.k_proj.weight.safetensors", "model.layers.5.self_attn.o_proj.weight": "model-00148-model.layers.5.self_attn.o_proj.weight.safetensors", "model.layers.5.self_attn.q_proj.weight": "model-00149-model.layers.5.self_attn.q_proj.weight.safetensors", "model.layers.5.self_attn.v_proj.weight": "model-00150-model.layers.5.self_attn.v_proj.weight.safetensors", "model.layers.6.input_layernorm.weight": "model-00151-model.layers.6.input_layernorm.weight.safetensors", "model.layers.6.mlp.down_proj.weight": "model-00152-model.layers.6.mlp.down_proj.weight.safetensors", "model.layers.6.mlp.gate_proj.weight": "model-00153-model.layers.6.mlp.gate_proj.weight.safetensors", "model.layers.6.mlp.up_proj.weight": "model-00154-model.layers.6.mlp.up_proj.weight.safetensors", "model.layers.6.post_attention_layernorm.weight": "model-00155-model.layers.6.post_attention_layernorm.weight.safetensors", "model.layers.6.self_attn.k_proj.weight": "model-00156-model.layers.6.self_attn.k_proj.weight.safetensors", "model.layers.6.self_attn.o_proj.weight": "model-00157-model.layers.6.self_attn.o_proj.weight.safetensors", "model.layers.6.self_attn.q_proj.weight": "model-00158-model.layers.6.self_attn.q_proj.weight.safetensors", "model.layers.6.self_attn.v_proj.weight": "model-00159-model.layers.6.self_attn.v_proj.weight.safetensors", "model.layers.7.input_layernorm.weight": "model-00160-model.layers.7.input_layernorm.weight.safetensors", "model.layers.7.mlp.down_proj.weight": "model-00161-model.layers.7.mlp.down_proj.weight.safetensors", "model.layers.7.mlp.gate_proj.weight": "model-00162-model.layers.7.mlp.gate_proj.weight.safetensors", "model.layers.7.mlp.up_proj.weight": "model-00163-model.layers.7.mlp.up_proj.weight.safetensors", "model.layers.7.post_attention_layernorm.weight": "model-00164-model.layers.7.post_attention_layernorm.weight.safetensors", "model.layers.7.self_attn.k_proj.weight": "model-00165-model.layers.7.self_attn.k_proj.weight.safetensors", "model.layers.7.self_attn.o_proj.weight": "model-00166-model.layers.7.self_attn.o_proj.weight.safetensors", "model.layers.7.self_attn.q_proj.weight": "model-00167-model.layers.7.self_attn.q_proj.weight.safetensors", "model.layers.7.self_attn.v_proj.weight": "model-00168-model.layers.7.self_attn.v_proj.weight.safetensors", "model.layers.8.input_layernorm.weight": "model-00169-model.layers.8.input_layernorm.weight.safetensors", "model.layers.8.mlp.down_proj.weight": "model-00170-model.layers.8.mlp.down_proj.weight.safetensors", "model.layers.8.mlp.gate_proj.weight": "model-00171-model.layers.8.mlp.gate_proj.weight.safetensors", "model.layers.8.mlp.up_proj.weight": "model-00172-model.layers.8.mlp.up_proj.weight.safetensors", "model.layers.8.post_attention_layernorm.weight": "model-00173-model.layers.8.post_attention_layernorm.weight.safetensors", "model.layers.8.self_attn.k_proj.weight": "model-00174-model.layers.8.self_attn.k_proj.weight.safetensors", "model.layers.8.self_attn.o_proj.weight": "model-00175-model.layers.8.self_attn.o_proj.weight.safetensors", "model.layers.8.self_attn.q_proj.weight": "model-00176-model.layers.8.self_attn.q_proj.weight.safetensors", "model.layers.8.self_attn.v_proj.weight": "model-00177-model.layers.8.self_attn.v_proj.weight.safetensors", "model.layers.9.input_layernorm.weight": "model-00178-model.layers.9.input_layernorm.weight.safetensors", "model.layers.9.mlp.down_proj.weight": "model-00179-model.layers.9.mlp.down_proj.weight.safetensors", "model.layers.9.mlp.gate_proj.weight": "model-00180-model.layers.9.mlp.gate_proj.weight.safetensors", "model.layers.9.mlp.up_proj.weight": "model-00181-model.layers.9.mlp.up_proj.weight.safetensors", "model.layers.9.post_attention_layernorm.weight": "model-00182-model.layers.9.post_attention_layernorm.weight.safetensors", "model.layers.9.self_attn.k_proj.weight": "model-00183-model.layers.9.self_attn.k_proj.weight.safetensors", "model.layers.9.self_attn.o_proj.weight": "model-00184-model.layers.9.self_attn.o_proj.weight.safetensors", "model.layers.9.self_attn.q_proj.weight": "model-00185-model.layers.9.self_attn.q_proj.weight.safetensors", "model.layers.9.self_attn.v_proj.weight": "model-00186-model.layers.9.self_attn.v_proj.weight.safetensors", "model.norm.weight": "model-00253-model.norm.weight.safetensors"}}